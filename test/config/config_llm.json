{
  "llm_config": {
    "llama3": {
      "path":""
    },
    "perspective": {
      "api_url": ""
    },
    "openai": {
      "key": "",
      "api_url": "",
      "parameters": {
        "temperature": 0
      }
    },
    "lmdeploy_openai": {
      "api_url": ""
    },
    "internvl": {
      "key": "",
      "api_url": "",
      "parameters": {
        "temperature": 0
      }
    }
  }
}